---
title: "ai is walking into the same trap web2 did"
publishedAt: "2026-01-28"
description: "openai adding ads, chatgpt censoring privacy tools, google scanning your emails — we've seen this movie before"
tags: ["ai", "privacy", "crypto"]
---

we've been here before.

remember when google's motto was "don't be evil"? when facebook was a fun way to share photos with college friends? when gmail was revolutionary because it gave you 1GB of free storage?

free is never free. you pay with your data. and now AI is speedrunning the exact same playbook.

## the web2 pattern

here's how it always goes:

1. **launch phase**: free, useful, no ads
2. **growth phase**: still free, minor data collection "to improve the product"
3. **capture phase**: you're locked in, your data is the product
4. **extraction phase**: ads everywhere, selling your data to third parties

google did it. facebook did it. instagram, tiktok, every "free" platform — same story, different decade.

now watch what's happening with AI.

## openai announces ads

in january 2026, openai announced they're exploring advertising. shocking absolutely no one who's been paying attention.

chatgpt has 300 million users. that's a goldmine of intimate data — your questions, your code, your secrets. the things you ask an AI are often things you wouldn't type into google. more personal. more valuable.

the advertising model isn't just about showing you banner ads. it's about building a profile of who you are based on every interaction, then selling access to that profile.

## chatgpt is already censoring — without being asked

here's something most people missed. naomi brockwell (privacy advocate with 500k+ youtube subscribers) discovered that chatgpt was removing mentions of privacy tools from her content summaries.

not because openai was asked to. not because of legal requirements. the AI was proactively sanitizing content about one-time phone numbers and privacy-preserving crypto tools.

think about that. the AI you're trusting to help you is quietly removing information about how to protect yourself from... AI companies collecting your data.

this isn't a bug. it's the feature.

## google is going turbo

while openai is just starting down this path, google is already sprinting.

gemini is being integrated into gmail, calendar, and docs. sounds convenient! now your AI assistant can read all your emails, schedule your meetings, and understand every document you write.

the same company whose entire business model is selling targeted ads now has an AI reading your private communications.

```
# what you see:
"Hey, I can help you draft that email!"

# what's actually happening:
user_profile.add({
  "income_bracket": "high",
  "health_concerns": ["back pain", "sleep issues"],
  "buying_intent": ["new mattress", "standing desk"],
  "negotiating_salary": true
})
```

this isn't paranoia. this is literally their business model.

## "crypto could be linux in 15 years"

zooko wilcox, creator of zcash, made a sobering observation in a recent interview:

> "crypto could be like linux 15 years from now — something that a couple of mega corporations cost-optimize by using, while 99.9% of people are not empowered or benefited in any way."

linux won the server war. it's everywhere. amazon, google, netflix — all built on linux. but your grandma isn't running ubuntu. the liberation never reached normal people.

crypto risks the same fate. defi becomes infrastructure for tradfi. zero-knowledge proofs become something visa uses internally. but regular people still use apps that harvest their data and sell it to advertisers.

## the signal lesson

moxie marlinspike built signal — the gold standard of encrypted messaging. his insight was simple but profound:

if you could see everyone who had access to your messages in a normal app, it would look horrifying. the ceo, the sysadmins, the government agencies requesting data, the advertisers building profiles. signal shows you the truth: just you and the person you're talking to.

the cypherpunk movement tried for decades to get people to use pgp and encrypt their own stuff. it never worked. the tools were built by nerds for nerds.

signal succeeded because it started from the user experience, not the technology. encryption happens in the background. you just... message people.

AI needs its signal moment.

## moxie is building private AI

here's the hopeful part: moxie marlinspike is reportedly working on a privacy-preserving AI product.

think about what signal did for messaging. now imagine that for AI — a tool where your conversations genuinely stay private. no profile building. no data harvesting. no advertising model waiting in the wings.

this matters because the current trajectory is terrifying. in five years, every major AI will be ad-supported, which means surveillance-supported. your most intimate questions will be training data for better targeting.

## telegram is a honeypot

while we're here, let's address the elephant in the room. zooko was blunt about it:

> "telegram is a freaking honeypot. it just makes me despair that all the crypto people use telegram and think it's secure."

telegram's encryption is opt-in (end-to-end only for "secret chats"), group chats aren't encrypted at all, and the company has a history of complying with government requests.

if you're discussing anything sensitive — trades, business strategy, anything — telegram is not your friend.

## the economic feedback loop is broken

here's why privacy tools struggle: they don't have silicon valley's feedback loop.

better product → more users → more data/ads → more money → better product

signal actually loses money with more users. every message costs them bandwidth and storage with zero revenue.

the advertising model is evil, but it works. privacy-preserving alternatives need a sustainable economic model that isn't "billionaire philanthropy" or "pray for donations."

zooko's solution is straightforward: people should pay for products. sounds obvious, but it's radical in an era where everything is "free."

## what you can do

1. **pay for the AI tools you use** — if you're not paying, you're the product
2. **local models are getting good** — ollama + mistral/llama can handle most tasks without sending data anywhere
3. **audit your stack** — which tools are you trusting with sensitive data?
4. **support privacy-first alternatives** — when moxie's AI ships, try it

the window is closing. right now there are still AI tools that aren't surveillance machines. in five years, the capture will be complete for most mainstream products.

history doesn't repeat, but it rhymes. we watched this happen with web2 and did nothing. this time, maybe we build the alternative before it's too late.

---

*the zcash founder interview is worth a listen if you want the full philosophical context. zooko's been in the cypherpunk trenches for decades and his perspective on why privacy tools keep failing to reach mainstream adoption is essential.*
